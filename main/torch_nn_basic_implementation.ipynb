{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87ad48a-8228-4b60-bd58-0b2c164c2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorly as tl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import QuantLib as ql\n",
    "import pysabr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05cf25a0-6bfc-4b50-af50-61c2e34166a9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2efe9866-c5f0-4893-915e-85f642f4ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tensorly.tenalg import inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1e0df1-2881-497f-8cee-b5fb0d24f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend('pytorch')\n",
    "batch_size = 64\n",
    "device = 'cpu'\n",
    "kf = KFold(n_splits=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19320c42-a1c5-4cf9-955d-cf2ea1b5f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "raw_data = pd.read_csv('fdm_hagan_vol.csv')\n",
    "test_raw_data = pd.read_csv('fdm_hagan_vol_test.csv')\n",
    "raw_data[\"Error\"] = (raw_data[\"FDM_vol\"] - raw_data[\"Hagan_vol\"]).abs()\n",
    "test_raw_data[\"Error\"] = (test_raw_data[\"FDM_vol\"] - test_raw_data[\"Hagan_vol\"]).abs()\n",
    "\n",
    "X = raw_data.drop([\"FDM_vol\", \"Hagan_vol\", \"Error\"], axis=1).values\n",
    "y = raw_data[\"Error\"].values\n",
    "X_test = test_raw_data.drop([\"FDM_vol\", \"Hagan_vol\", \"Error\"], axis=1).values\n",
    "y_test = test_raw_data[\"Error\"].values\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9e5b6a-4ea4-479b-9b86-6ab79cd966d4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR()\n",
      "[ 0.00075146 -0.04030514 -0.01026842 ...  0.00205002  0.00258336\n",
      "  0.04109529] \n",
      "\n",
      "RMSE:  0.0327799483505655\n",
      "SGDRegressor()\n",
      "[ 0.08826189  0.00954725  0.04439383 ... -0.02209945 -0.0263771\n",
      "  0.11485972] \n",
      "\n",
      "RMSE:  0.056796939410364435\n",
      "BayesianRidge()\n",
      "[ 0.08879069  0.01012903  0.04427379 ... -0.0222724  -0.026768\n",
      "  0.11495062] \n",
      "\n",
      "RMSE:  0.05684879902113361\n",
      "LassoLars()\n",
      "[0.07139829 0.07139829 0.07139829 ... 0.07139829 0.07139829 0.07139829] \n",
      "\n",
      "RMSE:  0.10174129528515419\n",
      "ARDRegression()\n",
      "[ 0.08830367  0.01032178  0.04371237 ... -0.02229401 -0.02698608\n",
      "  0.11395563] \n",
      "\n",
      "RMSE:  0.056854148967893786\n",
      "PassiveAggressiveRegressor()\n",
      "[ 0.06342781 -0.00552001  0.04139412 ... -0.0362765  -0.05068135\n",
      "  0.0721878 ] \n",
      "\n",
      "RMSE:  0.06603461069169445\n",
      "TheilSenRegressor(max_subpopulation=10000)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import linear_model\n",
    "# from sklearn import svm\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# classifiers = [\n",
    "#     svm.SVR(),\n",
    "#     linear_model.SGDRegressor(),\n",
    "#     linear_model.BayesianRidge(),\n",
    "#     linear_model.LassoLars(),\n",
    "#     linear_model.ARDRegression(),\n",
    "#     linear_model.PassiveAggressiveRegressor(),\n",
    "#     linear_model.TheilSenRegressor(),\n",
    "#     linear_model.LinearRegression()]\n",
    "\n",
    "# for item in classifiers:\n",
    "#     print(item)\n",
    "#     clf = item\n",
    "#     clf.fit(X, y)\n",
    "#     print(clf.predict(X_test),'\\n')\n",
    "#     print(\"RMSE: \",mean_squared_error(y_test, clf.predict(X_test), squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebc539ea-1e24-4176-89ae-e4857e9c8fa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/35/cc6425yn4fxg8fg8lb2w3mjr0000gn/T/ipykernel_8204/2855262528.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogistic_regression_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogistic_regression_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_logreg_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1514\u001b[0m             \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"liblinear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saga\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m         )\n\u001b[0;32m-> 1516\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     ]:\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "# logistic_regression_model = LogisticRegression()\n",
    "# logistic_regression_model.fit(X, y)\n",
    "# y_logreg_pred = logistic_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba1146ca-a95f-4201-acd2-0bab785f848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(X)\n",
    "y = torch.FloatTensor(y)\n",
    "y = torch.reshape(y, shape=(-1,1))\n",
    "\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "y_test = torch.reshape(y_test, shape=(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6347f776-3843-42b6-8d04-92bb39fd9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X, y)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "834ecfb2-3c57-46fc-8937-bf3e0ac2bde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(6, 20, device=device),\n",
    "                      nn.Linear(20,100),\n",
    "                      nn.Linear(100,400),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(400,10),           \n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(10,1),\n",
    "                      nn.Tanh()\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "n_epochs = 20\n",
    "# batch_size = 64\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed0fec60-d8a5-475d-aaaa-c467c13a6092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/553320 (0%)]\tLoss: 0.000013\n",
      "Train Epoch: 1 [64000/553320 (12%)]\tLoss: 0.000005\n",
      "Train Epoch: 1 [128000/553320 (23%)]\tLoss: 0.000009\n",
      "Train Epoch: 1 [192000/553320 (35%)]\tLoss: 0.000004\n",
      "Train Epoch: 1 [256000/553320 (46%)]\tLoss: 0.000034\n",
      "Train Epoch: 1 [320000/553320 (58%)]\tLoss: 0.000005\n",
      "Train Epoch: 1 [384000/553320 (69%)]\tLoss: 0.000004\n",
      "Train Epoch: 1 [448000/553320 (81%)]\tLoss: 0.000007\n",
      "Train Epoch: 1 [512000/553320 (93%)]\tLoss: 0.000001\n",
      "mean: 2.072007843079149e-11\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 2 [0/553320 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 2 [64000/553320 (12%)]\tLoss: 0.000005\n",
      "Train Epoch: 2 [128000/553320 (23%)]\tLoss: 0.000005\n",
      "Train Epoch: 2 [192000/553320 (35%)]\tLoss: 0.000004\n",
      "Train Epoch: 2 [256000/553320 (46%)]\tLoss: 0.000005\n",
      "Train Epoch: 2 [320000/553320 (58%)]\tLoss: 0.000003\n",
      "Train Epoch: 2 [384000/553320 (69%)]\tLoss: 0.000014\n",
      "Train Epoch: 2 [448000/553320 (81%)]\tLoss: 0.000002\n",
      "Train Epoch: 2 [512000/553320 (93%)]\tLoss: 0.000006\n",
      "mean: 6.662845275506868e-11\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 3 [0/553320 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 3 [64000/553320 (12%)]\tLoss: 0.000003\n",
      "Train Epoch: 3 [128000/553320 (23%)]\tLoss: 0.000002\n",
      "Train Epoch: 3 [192000/553320 (35%)]\tLoss: 0.000002\n",
      "Train Epoch: 3 [256000/553320 (46%)]\tLoss: 0.000001\n",
      "Train Epoch: 3 [320000/553320 (58%)]\tLoss: 0.000004\n",
      "Train Epoch: 3 [384000/553320 (69%)]\tLoss: 0.000002\n",
      "Train Epoch: 3 [448000/553320 (81%)]\tLoss: 0.000001\n",
      "Train Epoch: 3 [512000/553320 (93%)]\tLoss: 0.000003\n",
      "mean: 2.422036460281163e-10\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 4 [0/553320 (0%)]\tLoss: 0.000021\n",
      "Train Epoch: 4 [64000/553320 (12%)]\tLoss: 0.000005\n",
      "Train Epoch: 4 [128000/553320 (23%)]\tLoss: 0.000001\n",
      "Train Epoch: 4 [192000/553320 (35%)]\tLoss: 0.000001\n",
      "Train Epoch: 4 [256000/553320 (46%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [320000/553320 (58%)]\tLoss: 0.000001\n",
      "Train Epoch: 4 [384000/553320 (69%)]\tLoss: 0.000001\n",
      "Train Epoch: 4 [448000/553320 (81%)]\tLoss: 0.000001\n",
      "Train Epoch: 4 [512000/553320 (93%)]\tLoss: 0.000001\n",
      "mean: 1.4795989086713313e-11\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 5 [0/553320 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 5 [64000/553320 (12%)]\tLoss: 0.000001\n",
      "Train Epoch: 5 [128000/553320 (23%)]\tLoss: 0.000001\n",
      "Train Epoch: 5 [192000/553320 (35%)]\tLoss: 0.000001\n",
      "Train Epoch: 5 [256000/553320 (46%)]\tLoss: 0.000003\n",
      "Train Epoch: 5 [320000/553320 (58%)]\tLoss: 0.000003\n",
      "Train Epoch: 5 [384000/553320 (69%)]\tLoss: 0.000002\n",
      "Train Epoch: 5 [448000/553320 (81%)]\tLoss: 0.000002\n",
      "Train Epoch: 5 [512000/553320 (93%)]\tLoss: 0.000002\n",
      "mean: 3.812801810387789e-11\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 6 [0/553320 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 6 [64000/553320 (12%)]\tLoss: 0.000004\n",
      "Train Epoch: 6 [128000/553320 (23%)]\tLoss: 0.000003\n",
      "Train Epoch: 6 [192000/553320 (35%)]\tLoss: 0.000005\n",
      "Train Epoch: 6 [256000/553320 (46%)]\tLoss: 0.000004\n",
      "Train Epoch: 6 [320000/553320 (58%)]\tLoss: 0.000000\n",
      "Train Epoch: 6 [384000/553320 (69%)]\tLoss: 0.000004\n",
      "Train Epoch: 6 [448000/553320 (81%)]\tLoss: 0.000000\n",
      "Train Epoch: 6 [512000/553320 (93%)]\tLoss: 0.000003\n",
      "mean: 3.866579972866546e-11\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 7 [0/553320 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 7 [64000/553320 (12%)]\tLoss: 0.000002\n",
      "Train Epoch: 7 [128000/553320 (23%)]\tLoss: 0.000002\n",
      "Train Epoch: 7 [192000/553320 (35%)]\tLoss: 0.000001\n",
      "Train Epoch: 7 [256000/553320 (46%)]\tLoss: 0.000002\n",
      "Train Epoch: 7 [320000/553320 (58%)]\tLoss: 0.000001\n",
      "Train Epoch: 7 [384000/553320 (69%)]\tLoss: 0.000032\n",
      "Train Epoch: 7 [448000/553320 (81%)]\tLoss: 0.000003\n",
      "Train Epoch: 7 [512000/553320 (93%)]\tLoss: 0.000001\n",
      "mean: 3.086219127479417e-11\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 8 [0/553320 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 8 [64000/553320 (12%)]\tLoss: 0.000002\n",
      "Train Epoch: 8 [128000/553320 (23%)]\tLoss: 0.000003\n",
      "Train Epoch: 8 [192000/553320 (35%)]\tLoss: 0.000004\n",
      "Train Epoch: 8 [256000/553320 (46%)]\tLoss: 0.000001\n",
      "Train Epoch: 8 [320000/553320 (58%)]\tLoss: 0.000001\n",
      "Train Epoch: 8 [384000/553320 (69%)]\tLoss: 0.000004\n",
      "Train Epoch: 8 [448000/553320 (81%)]\tLoss: 0.000002\n",
      "Train Epoch: 8 [512000/553320 (93%)]\tLoss: 0.000001\n",
      "mean: 2.1185345144836276e-11\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 9 [0/553320 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 9 [64000/553320 (12%)]\tLoss: 0.000001\n",
      "Train Epoch: 9 [128000/553320 (23%)]\tLoss: 0.000002\n",
      "Train Epoch: 9 [192000/553320 (35%)]\tLoss: 0.000001\n",
      "Train Epoch: 9 [256000/553320 (46%)]\tLoss: 0.000001\n",
      "Train Epoch: 9 [320000/553320 (58%)]\tLoss: 0.000000\n",
      "Train Epoch: 9 [384000/553320 (69%)]\tLoss: 0.000001\n",
      "Train Epoch: 9 [448000/553320 (81%)]\tLoss: 0.000005\n",
      "Train Epoch: 9 [512000/553320 (93%)]\tLoss: 0.000001\n",
      "mean: 1.2708093258262387e-11\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 10 [0/553320 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 10 [64000/553320 (12%)]\tLoss: 0.000000\n",
      "Train Epoch: 10 [128000/553320 (23%)]\tLoss: 0.000001\n",
      "Train Epoch: 10 [192000/553320 (35%)]\tLoss: 0.000000\n",
      "Train Epoch: 10 [256000/553320 (46%)]\tLoss: 0.000001\n",
      "Train Epoch: 10 [320000/553320 (58%)]\tLoss: 0.000003\n",
      "Train Epoch: 10 [384000/553320 (69%)]\tLoss: 0.000000\n",
      "Train Epoch: 10 [448000/553320 (81%)]\tLoss: 0.000000\n",
      "Train Epoch: 10 [512000/553320 (93%)]\tLoss: 0.000007\n",
      "mean: 2.5674015864673994e-12\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 11 [0/553320 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 11 [64000/553320 (12%)]\tLoss: 0.000004\n",
      "Train Epoch: 11 [128000/553320 (23%)]\tLoss: 0.000000\n",
      "Train Epoch: 11 [192000/553320 (35%)]\tLoss: 0.000004\n",
      "Train Epoch: 11 [256000/553320 (46%)]\tLoss: 0.000002\n",
      "Train Epoch: 11 [320000/553320 (58%)]\tLoss: 0.000000\n",
      "Train Epoch: 11 [384000/553320 (69%)]\tLoss: 0.000000\n",
      "Train Epoch: 11 [448000/553320 (81%)]\tLoss: 0.000001\n",
      "Train Epoch: 11 [512000/553320 (93%)]\tLoss: 0.000003\n",
      "mean: 1.4591948526224141e-12\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 12 [0/553320 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 12 [64000/553320 (12%)]\tLoss: 0.000003\n",
      "Train Epoch: 12 [128000/553320 (23%)]\tLoss: 0.000003\n",
      "Train Epoch: 12 [192000/553320 (35%)]\tLoss: 0.000001\n",
      "Train Epoch: 12 [256000/553320 (46%)]\tLoss: 0.000001\n",
      "Train Epoch: 12 [320000/553320 (58%)]\tLoss: 0.000001\n",
      "Train Epoch: 12 [384000/553320 (69%)]\tLoss: 0.000001\n",
      "Train Epoch: 12 [448000/553320 (81%)]\tLoss: 0.000005\n",
      "Train Epoch: 12 [512000/553320 (93%)]\tLoss: 0.000006\n",
      "mean: 2.6195827191460852e-12\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 13 [0/553320 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 13 [64000/553320 (12%)]\tLoss: 0.000000\n",
      "Train Epoch: 13 [128000/553320 (23%)]\tLoss: 0.000002\n",
      "Train Epoch: 13 [192000/553320 (35%)]\tLoss: 0.000033\n",
      "Train Epoch: 13 [256000/553320 (46%)]\tLoss: 0.000001\n",
      "Train Epoch: 13 [320000/553320 (58%)]\tLoss: 0.000001\n",
      "Train Epoch: 13 [384000/553320 (69%)]\tLoss: 0.000000\n",
      "Train Epoch: 13 [448000/553320 (81%)]\tLoss: 0.000000\n",
      "Train Epoch: 13 [512000/553320 (93%)]\tLoss: 0.000001\n",
      "mean: 1.4099740472395261e-11\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 14 [0/553320 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 14 [64000/553320 (12%)]\tLoss: 0.000000\n",
      "Train Epoch: 14 [128000/553320 (23%)]\tLoss: 0.000003\n",
      "Train Epoch: 14 [192000/553320 (35%)]\tLoss: 0.000001\n",
      "Train Epoch: 14 [256000/553320 (46%)]\tLoss: 0.000000\n",
      "Train Epoch: 14 [320000/553320 (58%)]\tLoss: 0.000001\n",
      "Train Epoch: 14 [384000/553320 (69%)]\tLoss: 0.000003\n",
      "Train Epoch: 14 [448000/553320 (81%)]\tLoss: 0.000000\n",
      "Train Epoch: 14 [512000/553320 (93%)]\tLoss: 0.000000\n",
      "mean: 2.4749774452104134e-10\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 15 [0/553320 (0%)]\tLoss: 0.000011\n",
      "Train Epoch: 15 [64000/553320 (12%)]\tLoss: 0.000005\n",
      "Train Epoch: 15 [128000/553320 (23%)]\tLoss: 0.000001\n",
      "Train Epoch: 15 [192000/553320 (35%)]\tLoss: 0.000000\n",
      "Train Epoch: 15 [256000/553320 (46%)]\tLoss: 0.000003\n",
      "Train Epoch: 15 [320000/553320 (58%)]\tLoss: 0.000000\n",
      "Train Epoch: 15 [384000/553320 (69%)]\tLoss: 0.000000\n",
      "Train Epoch: 15 [448000/553320 (81%)]\tLoss: 0.000002\n",
      "Train Epoch: 15 [512000/553320 (93%)]\tLoss: 0.000002\n",
      "mean: 6.592148268230735e-12\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 16 [0/553320 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 16 [64000/553320 (12%)]\tLoss: 0.000001\n",
      "Train Epoch: 16 [128000/553320 (23%)]\tLoss: 0.000000\n",
      "Train Epoch: 16 [192000/553320 (35%)]\tLoss: 0.000001\n",
      "Train Epoch: 16 [256000/553320 (46%)]\tLoss: 0.000003\n",
      "Train Epoch: 16 [320000/553320 (58%)]\tLoss: 0.000004\n",
      "Train Epoch: 16 [384000/553320 (69%)]\tLoss: 0.000001\n",
      "Train Epoch: 16 [448000/553320 (81%)]\tLoss: 0.000001\n",
      "Train Epoch: 16 [512000/553320 (93%)]\tLoss: 0.000000\n",
      "mean: 2.2776839442295582e-11\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 17 [0/553320 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 17 [64000/553320 (12%)]\tLoss: 0.000001\n",
      "Train Epoch: 17 [128000/553320 (23%)]\tLoss: 0.000000\n",
      "Train Epoch: 17 [192000/553320 (35%)]\tLoss: 0.000001\n",
      "Train Epoch: 17 [256000/553320 (46%)]\tLoss: 0.000004\n",
      "Train Epoch: 17 [320000/553320 (58%)]\tLoss: 0.000000\n",
      "Train Epoch: 17 [384000/553320 (69%)]\tLoss: 0.000000\n",
      "Train Epoch: 17 [448000/553320 (81%)]\tLoss: 0.000001\n",
      "Train Epoch: 17 [512000/553320 (93%)]\tLoss: 0.000001\n",
      "mean: 3.341905528350675e-12\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 18 [0/553320 (0%)]\tLoss: 0.000000\n",
      "Train Epoch: 18 [64000/553320 (12%)]\tLoss: 0.000000\n",
      "Train Epoch: 18 [128000/553320 (23%)]\tLoss: 0.000001\n",
      "Train Epoch: 18 [192000/553320 (35%)]\tLoss: 0.000001\n",
      "Train Epoch: 18 [256000/553320 (46%)]\tLoss: 0.000002\n",
      "Train Epoch: 18 [320000/553320 (58%)]\tLoss: 0.000000\n",
      "Train Epoch: 18 [384000/553320 (69%)]\tLoss: 0.000001\n",
      "Train Epoch: 18 [448000/553320 (81%)]\tLoss: 0.000001\n",
      "Train Epoch: 18 [512000/553320 (93%)]\tLoss: 0.000000\n",
      "mean: 7.425695475182792e-12\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n",
      "Train Epoch: 19 [0/553320 (0%)]\tLoss: 0.000001\n",
      "Train Epoch: 19 [64000/553320 (12%)]\tLoss: 0.000002\n",
      "Train Epoch: 19 [128000/553320 (23%)]\tLoss: 0.000001\n",
      "Train Epoch: 19 [192000/553320 (35%)]\tLoss: 0.000004\n",
      "Train Epoch: 19 [256000/553320 (46%)]\tLoss: 0.000001\n",
      "Train Epoch: 19 [320000/553320 (58%)]\tLoss: 0.000000\n",
      "Train Epoch: 19 [384000/553320 (69%)]\tLoss: 0.000005\n",
      "Train Epoch: 19 [448000/553320 (81%)]\tLoss: 0.000009\n",
      "Train Epoch: 19 [512000/553320 (93%)]\tLoss: 0.000001\n",
      "mean: 1.720403160210271e-11\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 0/50000 (0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(n_epoch):\n",
    "    model.train()\n",
    "    for i, (features, error) in enumerate(train_loader):\n",
    "        features, error = features.to(device), error.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(features)\n",
    "        loss = torch.nn.functional.mse_loss(output,error)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 1000 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(features), len(train_loader.dataset),\n",
    "                100. * i / len(train_loader), loss))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for features, error in test_loader:\n",
    "        features, error = features.to(device), error.to(device)\n",
    "        output = model(features)\n",
    "        test_loss = torch.nn.functional.mse_loss(output,error)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(error.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('mean: {}'.format(test_loss))\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "       100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "for epoch in range(1, n_epochs):\n",
    "    train(epoch)\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666bf043-16a9-4a76-8dea-f00fd4f015bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n",
    "        \n",
    "        self.trl = TRL(ranks=(10, 3, 3, 10), input_size=(batch_size, 50, 4, 4), output_size=(batch_size,10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = self.trl(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "model = Net()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
